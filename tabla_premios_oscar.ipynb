{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Extracción de Tablas de los Premios Oscar con Beautiful Soup\n",
    "    \n",
    "    En esta fase, trabajarán con la biblioteca Beautiful Soup para extraer información relevante de las tablas de los premios Oscar desde 2000.\n",
    "La tabla la encontrarás en este link: https://en.wikipedia.org/wiki/Academy_Awards\n",
    "\n",
    "La información que deberás extraer es:\n",
    "        Fecha de la ceremonia.\n",
    "        Mejor película.\n",
    "        Mejor director.\n",
    "        Mejor actor.\n",
    "    Mejor actriz.\n",
    "\n",
    "NOTA: La información deberá ser almacenada en una lista de tuplas. Cada tupla corresponderá a una película. Siguiendo el siguiente ejemplo: [(1990, 'Driving Miss Daisy', 'O. Stone', \"D. Day-Lewis\",' J. Tandy' ), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de tablas que tenemos en la página web es: 28\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# definimos la url de la página de la vamos a sacar datos\n",
    "url_premios_oscar = \"https://en.wikipedia.org/wiki/Academy_Awards\"\n",
    "\n",
    "# hacemos la request a la página de la que queremos sacar la info\n",
    "res_premios_oscar = requests.get(url_premios_oscar)\n",
    "\n",
    "if res_premios_oscar.status_code != 200:                  # Comprueba si la respuesta no fue exitosa (código de estado distinto de 200).\n",
    "    print(f\"El motivo por el que la llamada falló es {res_premios_oscar.reason}\")\n",
    "else:\n",
    "    # creamos el objeto BeautifulSoup para poder acceder al contenido solicitado\n",
    "    sopa_premios = BeautifulSoup(res_premios_oscar.content, 'html.parser')\n",
    "\n",
    "# recordemos que el método .prettify nos permite mostrar de una forma más amigable los resultados obtenidos de la sopa\n",
    "#print(sopa_premios.prettify())\n",
    "\n",
    "# vamos a seguir usando el metodo \".find_all()\", pero en este caso lo que buscaremos son todas las tablas que tenemos en la página web.\n",
    "tablas = sopa_premios.find_all(\"table\")\n",
    "\n",
    "print(\"El número de tablas que tenemos en la página web es:\", len(tablas))\n",
    "\n",
    "#Empiezo de momento a buscar la tabla que contiene los premios al mejor director del año 2000\n",
    "#table = sopa_premios.find('table', {'': ''})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos que tenemos en cada una de las tablas que hemos extraído de la página web. \n",
    "print(\"En la tabla 1 tenemos: \\n \", tablas[0])\n",
    "print(\"\\n---------------------\\n\")\n",
    "\n",
    "print(\"En la tabla 2 tenemos: \\n\", tablas[1])\n",
    "print(\"\\n---------------------\\n\")\n",
    "\n",
    "print(\"En la tabla 3 tenemos: \\n\", tablas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la página de Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Academy_Awards\"\n",
    "\n",
    "# Obtener el contenido de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Encontrar la tabla específica para Mejor Director desde 2000\n",
    "tables = soup.find_all('table', {'class':'wikitable'})\n",
    "\n",
    "# Si encuentras la tabla correcta, conviértela en un DataFrame de pandas\n",
    "# Por ejemplo, si la tabla de Mejor Director es la primera:\n",
    "# Esto podría cambiar, debes identificar la tabla correcta en la lista tables\n",
    "for table in tables:\n",
    "    if \"Best Director\" in table.text:\n",
    "        df = pd.read_html(str(table))[0]\n",
    "        break\n",
    "\n",
    "# Filtrar las filas que correspondan a los años desde 2000\n",
    "df = df[df['Year'] >= 2000]\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
