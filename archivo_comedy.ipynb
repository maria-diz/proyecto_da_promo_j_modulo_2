{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "El motivo por el que la llamada falló es Bad Gateway\n",
      "Empty DataFrame\n",
      "Columns: [Titulo, Tipo, Año, Id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extraer_peliculas_rango (generos, año_ini, ano_fin):           # creo una funcion donde puedo sacar varios generos y el rango    \n",
    "    lista_pelis = []                                               # creo una lista vacia que contendrá tuplas como elementos       \n",
    "    for genero in generos:                                         # recorro los generos y dentro de los generos \n",
    "        for año in range(int(año_ini),int(ano_fin)+1):             # recorro los años en el rango entre año inicial y final \n",
    "            url = f\"https://dev.adalab.es/api/cinema/movies?year={año}&genre={genero}\"\n",
    "            llamada_peliculas = requests.get(url)                      #llamo a la url para ver todos los datos que tiene \n",
    "\n",
    "            if llamada_peliculas.status_code != 200:                  # Comprueba si la respuesta no fue exitosa (código de estado distinto de 200).\n",
    "                print(f\"El motivo por el que la llamada falló es {llamada_peliculas.reason}\") \n",
    "            else:\n",
    "                pelis_json = llamada_peliculas.json()        # Como la respuesta es correcta devuelvo los datos en formato json y los guardo en una \n",
    "                                                             #variable. lo que devuelve es diccionario con todas las info de la peliculas solicitadas\n",
    "        \n",
    "                for peli in pelis_json[\"results\"]:         # recorro la lista de diccionarios del json \n",
    "                    lista_pelis.append((peli[\"title\"],peli[\"type\"], peli[\"year\"], peli[\"id\"])) # por cada pelicula construyo una tupla y se va \n",
    "                                                                                                # añadiendo a la lista\n",
    "                \n",
    "    cabecera = [\"Titulo\",\"Tipo\",\"Año\",\"Id\"]                     \n",
    "    df = pd.DataFrame(lista_pelis, columns=cabecera)            # creo el  data frame con 2 parametros uno es la lista_pelis y el otro las cabeceras\n",
    "    print(df)\n",
    "\n",
    "\n",
    "extraer_peliculas_rango([\"Comedy\",\"Romance\"],\"1900\",\"1915\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Extracción de Tablas de los Premios Oscar con Beautiful Soup\n",
    "    \n",
    "    En esta fase, trabajarán con la biblioteca Beautiful Soup para extraer información relevante de las tablas de los premios Oscar desde 2000.\n",
    "La tabla la encontrarás en este link: https://en.wikipedia.org/wiki/Academy_Awards\n",
    "\n",
    "La información que deberás extraer es:\n",
    "        Fecha de la ceremonia.\n",
    "        Mejor película.\n",
    "        Mejor director.\n",
    "        Mejor actor.\n",
    "    Mejor actriz.\n",
    "\n",
    "NOTA: La información deberá ser almacenada en una lista de tuplas. Cada tupla corresponderá a una película. Siguiendo el siguiente ejemplo: [(1990, 'Driving Miss Daisy', 'O. Stone', \"D. Day-Lewis\",' J. Tandy' ), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La respuesta de la petición es: 200\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# definimos la url de la página de la vamos a sacar datos\n",
    "url_premios_oscar = \"https://en.wikipedia.org/wiki/Academy_Awards\"\n",
    "\n",
    "# hacemos la request a la página de la que queremos sacar la info\n",
    "res_premios_oscar = requests.get(url_premios_oscar)\n",
    "\n",
    "if res_premios_oscar.status_code != 200:                  # Comprueba si la respuesta no fue exitosa (código de estado distinto de 200).\n",
    "    print(f\"El motivo por el que la llamada falló es {res_premios_oscar.reason}\")\n",
    "else:\n",
    "    # creamos el objeto BeautifulSoup para poder acceder al contenido solicitado\n",
    "    sopa_premios = BeautifulSoup(res_premios_oscar.content, 'html.parser')\n",
    "\n",
    "# Empiezo de momento a buscar la tabla que contiene los premios al mejor director del año 2000\n",
    "table = sopa_premios.find('table', {'': ''})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "en la url de wikipedia los datos están en dispersos en varias tablas pero chat gpt me dice que solo hay una tabla : Wikitable, que no puedo identificar\n",
    "creo que tengo que usar css y xpath\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página de Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/Academy_Awards\"\n",
    "\n",
    "# Realizar la solicitud a la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Buscar la tabla que contiene los premios desde el año 2000\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Inicializar la lista para almacenar la información\n",
    "oscars_data = []\n",
    "\n",
    "# Iterar sobre las filas de la tabla\n",
    "for row in table.find_all('tr')[1:]:  # Saltar la primera fila que es el encabezado\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 5:  # Verifica que la fila tenga suficientes columnas\n",
    "        year = int(columns[0].text.strip())  # Año de la ceremonia\n",
    "        if year >= 2000:  # Filtrar los años desde el 2000 en adelante\n",
    "            date = columns[1].text.strip()  # Fecha de la ceremonia\n",
    "            best_picture = columns[2].text.strip()  # Mejor película\n",
    "            best_director = columns[3].text.strip()  # Mejor director\n",
    "            best_actor = columns[4].text.strip()  # Mejor actor\n",
    "            best_actress = columns[5].text.strip()  # Mejor actriz\n",
    "\n",
    "            # Crear una tupla con la información y agregarla a la lista\n",
    "            oscars_data.append((year, date, best_picture, best_director, best_actor, best_actress))\n",
    "\n",
    "# Mostrar la lista de tuplas\n",
    "for entry in oscars_data:\n",
    "    print(entry)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
